{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the Data Using Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample in the dataset has a unique ID. In the following code, when defining the generator, we first get the list of ID's from the RGB folder, then use the list of ID's to load the corresponding information of each sample. Associated with each sample is the following information (size and directory name for the training set are also listed):\n",
    "    1. RGB image (512 * 512 * 3) (train/images/rgb)\n",
    "    2. NIR image (512 * 512 * 1) (train/images/rgb)\n",
    "    3. Boundary (512 * 512 * 1) (train/boundaries)\n",
    "    4. Mask (512 * 512 * 1) (train/masks)\n",
    "The task of this project is to use the information above to predict for each pixel, which of the six categories it belons to:\n",
    "    1. Cloud shadow (512 * 512 * 1) (train/labels/cloud_shadow)\n",
    "    2. Double plant (512 * 512 * 1) (train/labels/double_plant)\n",
    "    3. Planter skip (512 * 512 * 1) (train/labels/planter_skip)\n",
    "    4. Standing water (512 * 512 * 1) (train/labels/standing_water)\n",
    "    5. Waterway (512 * 512 * 1) (train/labels/waterway)\n",
    "    6. Weed cluster (512 * 512 * 1) (train/labels/weed_cluster)\n",
    "If a pixel does not belong to any category above, it is considered to be\n",
    "    0. Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import image as mpimg\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Callable, Union\n",
    "from itertools import product\n",
    "\n",
    "#keras imports\n",
    "import keras\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.layers.convolutional import Conv2DTranspose\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Model\n",
    "from keras.callbacks import Callback\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_check(path, ntail, ids):\n",
    "    fignames = os.listdir(path)\n",
    "    for fig_id in ids:\n",
    "        if not fig_id + ntail in fignames:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def make_label(raw_labels):\n",
    "    \"\"\"\n",
    "    This function creates a 7-channel label from the six labels (add a background channel).\n",
    "    \"\"\"\n",
    "    stacked_labels = np.stack(raw_labels, axis=-1)\n",
    "    last_label = np.sum(stacked_labels, axis=-1) + 1\n",
    "    last_label[last_label > 1] = 0\n",
    "    # Put the background as the last channel of the label\n",
    "    full_labels =  np.concatenate([stacked_labels, last_label.reshape((512, 512, 1))], axis=-1)\n",
    "    return full_labels / np.linalg.norm(full_labels, axis=-1).reshape((512, 512, 1))\n",
    "    \n",
    "\n",
    "\n",
    "def img_gen(dataset='train'):\n",
    "    rgb_path = os.path.join(dataset, 'images', 'rgb')\n",
    "    nir_path = os.path.join(dataset, 'images', 'nir')\n",
    "    bdry_path = os.path.join(dataset, 'boundaries')\n",
    "    mask_path = os.path.join(dataset, 'masks')\n",
    "    label_names = ['cloud_shadow', 'double_plant', 'planter_skip', 'standing_water', 'waterway', 'weed_cluster']\n",
    "    label_paths = [os.path.join(dataset, 'labels', label_name) for label_name in label_names]\n",
    "    label = np.zeros((512,512,7))\n",
    "    \n",
    "    rgb_fig_names = os.listdir(rgb_path)\n",
    "    fig_ids = [fname[:-4] for fname in rgb_fig_names]\n",
    "    for fig_id in fig_ids:\n",
    "        rgb_img = mpimg.imread(os.path.join(rgb_path, fig_id + '.jpg'))\n",
    "        nir_img = mpimg.imread(os.path.join(nir_path, fig_id + '.jpg')).reshape((512, 512, 1))\n",
    "        bdry_img = mpimg.imread(os.path.join(bdry_path, fig_id + '.png'))\n",
    "        mask_img = mpimg.imread(os.path.join(mask_path, fig_id + '.png'))\n",
    "        if dataset != \"test\":\n",
    "            label_imgs = [mpimg.imread(os.path.join(label_path, fig_id + '.png')) for label_path in label_paths]\n",
    "            label = make_label(label_imgs)\n",
    "            \n",
    "        input_img = np.concatenate([rgb_img, nir_img], axis=2) / 255. # Concatenate the RGB and NIR\n",
    "        \n",
    "        yield fig_id, input_img, bdry_img, mask_img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "               kernel_initializer = 'he_normal', padding = 'same', activation = 'relu')(input_tensor)\n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same', activation = 'relu')(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def createUnet(input_img, n_filters = 16, dropout = 0.1):\n",
    "    #Down the Unet\n",
    "    conv1 = conv2d_block(input_img, n_filters)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(dropout)(pool1)\n",
    "    \n",
    "    conv2 = conv2d_block(pool1, n_filters*2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(dropout)(pool2)\n",
    "    \n",
    "    conv3 = conv2d_block(pool2, n_filters*4)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(dropout)(pool3)\n",
    "    \n",
    "    conv4 = conv2d_block(pool3, n_filters*8)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(dropout)(pool4)\n",
    "    #bottom of the unet\n",
    "    conv5 = conv2d_block(pool4, n_filters*16)\n",
    "    \n",
    "    #up the U\n",
    "    uconv4 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(conv5)\n",
    "    uconv4 = concatenate([uconv4, conv4])\n",
    "    uconv4 = conv2d_block(uconv4, n_filters*8)\n",
    "    \n",
    "    uconv3 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(uconv4)\n",
    "    uconv3 = concatenate([uconv3, conv3])\n",
    "    uconv3 = conv2d_block(uconv3, n_filters*4)\n",
    "    \n",
    "    uconv2 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(uconv3)\n",
    "    uconv2 = concatenate([uconv2, conv2])\n",
    "    uconv2 = conv2d_block(uconv2, n_filters*2)\n",
    "    \n",
    "    uconv1 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(uconv2)\n",
    "    uconv1 = concatenate([uconv1, conv1])\n",
    "    uconv1= conv2d_block(uconv1, n_filters*1)\n",
    "    \n",
    "    output = Conv2D(filters = 7, kernel_size = (1,1), activation = \"softmax\", padding = 'same')(uconv1)\n",
    "    model = Model(inputs=[input_img], outputs=[output])\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_img_gen(dataset='train'):\n",
    "    for fig_id, input_img, bdry_img, mask_img, label in img_gen(dataset):\n",
    "#     fig_id, input_img, bdry_img, mask_img, label =  next(img_gen(dataset))\n",
    "        final_mask = np.multiply(bdry_img, mask_img).reshape(512, 512, 1) # Form the final mask\n",
    "        masked_img = np.multiply(final_mask, input_img)\n",
    "    #     masked_img = tf.expand_dims(masked_img, axis =-1)\n",
    "        masked_img = masked_img.reshape(-1, 512, 512, 4)\n",
    "        if dataset != 'test':\n",
    "            label = label.reshape(-1, 512, 512, 7)\n",
    "            yield masked_img, label\n",
    "\n",
    "        else:\n",
    "            yield masked_img, fig_id\n",
    "# sample = next(img_gen('val'))\n",
    "# print(sample[1].shape, sample[4].shape)\n",
    "# print(next(masked_img_gen())[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    \"\"\"\n",
    "    A weighted version of keras.objectives.categorical_crossentropy\n",
    "\n",
    "    Variables:\n",
    "        weights: numpy array of shape (C,) where C is the number of classes\n",
    "\n",
    "    Usage:\n",
    "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
    "        loss = weighted_categorical_crossentropy(weights)\n",
    "        model.compile(loss=loss,optimizer='adam')\n",
    "    \"\"\"\n",
    "    weights = K.variable(weights)\n",
    "    def loss(y_true, y_pred):\n",
    "        # scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # calc\n",
    "        loss = y_true * K.log(y_pred) * weights\n",
    "        loss = -K.sum(loss, -1)\n",
    "        return loss\n",
    "        \n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_weighted_dice_loss(class_weights: Union[list, np.ndarray, tf.Tensor]) -> Callable[[tf.Tensor, tf.Tensor], tf.Tensor]:\n",
    "    \"\"\"\n",
    "    Weighted Dice loss.\n",
    "    Used as loss function for multi-class image segmentation with one-hot encoded masks.\n",
    "    :param class_weights: Class weight coefficients (Union[list, np.ndarray, tf.Tensor], len=<N_CLASSES>)\n",
    "    :return: Weighted Dice loss function (Callable[[tf.Tensor, tf.Tensor], tf.Tensor])\n",
    "    \"\"\"\n",
    "    if not isinstance(class_weights, tf.Tensor):\n",
    "        class_weights = tf.constant(class_weights)\n",
    "\n",
    "    def loss(y_true: tf.Tensor, y_pred: tf.Tensor) -> tf.Tensor:\n",
    "        \"\"\"\n",
    "        Compute weighted Dice loss.\n",
    "        :param y_true: True masks (tf.Tensor, shape=(<BATCH_SIZE>, <IMAGE_HEIGHT>, <IMAGE_WIDTH>, <N_CLASSES>))\n",
    "        :param y_pred: Predicted masks (tf.Tensor, shape=(<BATCH_SIZE>, <IMAGE_HEIGHT>, <IMAGE_WIDTH>, <N_CLASSES>))\n",
    "        :return: Weighted Dice loss (tf.Tensor, shape=(None,))\n",
    "        \"\"\"\n",
    "        axis_to_reduce = range(1, K.ndim(y_pred))  # Reduce all axis but first (batch)\n",
    "        numerator = y_true * y_pred * class_weights  # Broadcasting\n",
    "        numerator = 2. * K.sum(numerator, axis=axis_to_reduce)\n",
    "\n",
    "        denominator = (y_true + y_pred) * class_weights # Broadcasting\n",
    "        denominator = K.sum(denominator, axis=axis_to_reduce)\n",
    "\n",
    "        return 1 - numerator / denominator\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "input_img = Input((512, 512, 4), name='img')\n",
    "model = createUnet(input_img)\n",
    "weights = 10 * np.ones((7,))\n",
    "weights[0] = .3\n",
    "# weights = np.ones((7,7))\n",
    "# weights[:,6] = 1.3\n",
    "# weights[6,:] = 1.3\n",
    "model.compile(optimizer=\"adam\", loss=weighted_categorical_crossentropy(weights), metrics = [tf.keras.metrics.MeanIoU(num_classes=7)])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "input_img = Input((512, 512, 4), name='img')\n",
    "model = createUnet(input_img)\n",
    "weights = 10 * np.ones((7,), dtype=np.float32)\n",
    "weights[0] = .3\n",
    "# weights = np.ones((7,7))\n",
    "# weights[:,6] = 1.3\n",
    "# weights[6,:] = 1.3\n",
    "model.compile(optimizer=\"adam\", loss=multiclass_weighted_dice_loss(weights), metrics = [tf.keras.metrics.MeanIoU(num_classes=7)])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model, doing validation at the end of each epoch.\n",
    "epochs = 15\n",
    "model.fit(masked_img_gen('train'), epochs=epochs, steps_per_epoch=403, validation_data=masked_img_gen('val'), validation_steps=138, use_multiprocessing=False, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "if not os.path.isdir('preds'):\n",
    "    os.mkdir('preds')\n",
    "\n",
    "for mask_img, fig_id in masked_img_gen('test'):\n",
    "    \n",
    "    y_pred= model.predict(mask_img, verbose=0)\n",
    "    \n",
    "    pred_result = y_pred[0,:,:,:] # take the ith predictio\n",
    "    \n",
    "    \n",
    "    # Since we appended the background to the last channel, we need to bring it to the front when saving predictions\n",
    "    processed_result = np.concatenate([pred_result[:, :, -1].reshape((512, 512, 1)), pred_result[:, :, :-1]], axis=-1)\n",
    "#     print(processed_result.shape) # Should be (512, 512, 7)\n",
    "    # Convert the 7-channel result to 1-channel result and cast to uint8\n",
    "    \n",
    "    final_pred = np.argmax(processed_result, axis=-1).astype(np.uint8)\n",
    "#     print(final_pred.shape) # Should be (512, 512)\n",
    "    # Save the prediction\n",
    "    filename = os.path.join('preds', fig_id + '.png')\n",
    "    Image.fromarray(final_pred).save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = 12901//32\n",
    "print(steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_steps = 4431//32\n",
    "print(validation_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
